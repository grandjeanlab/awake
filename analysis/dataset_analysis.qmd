---
title: "analysis of the datasets"
author: "Joanes Grandjean"
date: "23/8/2025"
format: gfm
jupyter: python3
execute: 
  warning: false
---

specificity analysis of the rs scans. 

first define the plotting engine in interactive move
```{python}
#| eval: false
%autoindent 
import matplotlib
matplotlib.use('TkAgg') 

```

then import libraries and set functions that we will use later
```{python}

import pandas as pd
from os import listdir, makedirs
from os.path import join, isfile, isdir

import glob

import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

def get_fc_per_analysis(data_dir, df, analysis_list, frame_mask_dir, seed_ts_dir, seed_ref, seed_specific, seed_unspecific, seed_thalamus):
  from os.path import join
  try:
    for analysis in analysis_list:
        print("Running analysis for: " + analysis)
        #get the number of dropped frames for each scan and analysis
        p = join(data_dir, analysis, frame_mask_dir)
        df["dropped.frames." + analysis] = df["scan_dir"].apply(lambda x: dropped_frames(p,x))
        #get the connectivity specificity for s1 and thalamus
        p = join(data_dir, analysis, seed_ts_dir)
        df["s1.specific."+analysis]=df["scan_dir"].apply(lambda x: corr_seed(get_seed_ts(p, x, seed_ref), get_seed_ts(p, x, seed_specific)))
        df["s1.unspecific."+analysis]=df["scan_dir"].apply(lambda x: corr_seed(get_seed_ts(p, x, seed_ref), get_seed_ts(p, x, seed_unspecific)))
        df["thal.specific."+analysis]=df["scan_dir"].apply(lambda x: corr_seed(get_seed_ts(p, x, seed_ref), get_seed_ts(p, x, seed_thalamus)))
        df["s1.cat."+analysis] = df.apply(lambda x: specific_FC(x["s1.specific."+analysis], x["s1.unspecific."+analysis]), axis=1)
        df["thal.cat."+analysis] = df.apply(lambda x: specific_FC(x["thal.specific."+analysis], x["s1.unspecific."+analysis]), axis=1)
    return df
  except:
    pass

#write a function get_frame_mask that takes a path, scan_dir, and returns a mask
def dropped_frames(path, scan_dir):
    from os.path import join
    from os import listdir
    from pandas import read_table   
    try:
        frame_mask_path = join(path, scan_dir)
        frame_mask_file = listdir(frame_mask_path)[0]
        frame_mask_full = join(frame_mask_path, frame_mask_file)
        frame_mask_ts = read_table(join(frame_mask_path, frame_mask_file), names=['mask'], skiprows=[0])
        dropped_frames = list(frame_mask_ts["mask"]).count(False)
        return dropped_frames
    except: 
        pass

def total_frames(tmp_listdir, scan):
  try:
    from re import compile
    import nibabel as nib
    r = compile(".*"+scan)
    scan_file = list(filter(r.match, tmp_listdir))[0]
    return nib.load(scan_file).header["dim"][4]
  except:
    pass

def get_seed_ts(path, scan_dir, seed):
    from os.path import join
    from os import listdir
    from pandas import read_table   
    seed_prefix = "_seed_name_"
    try:
        seed_path = join(path, scan_dir, seed_prefix + seed)
        seed_file = listdir(seed_path)[0]
        seed_ts = read_table(join(seed_path, seed_file), names=['ts'])
        return seed_ts
    except:
        pass

# correlate the time series of two seeds
def corr_seed(seed1, seed2):
  try:
    return seed1["ts"].corr(seed2["ts"])
  except: 
    pass

# determine the correlation of a reference seed with specific, unspecific, and thalamus seeds
def specific_FC(specific_roi, unspecific_ROI):
  try:
    if (specific_roi>=0.1) and (unspecific_ROI<0.1):
        cat='Specific'
    elif (specific_roi>=0.1) and (unspecific_ROI>=0.1):
        cat='Non-specific'
    elif (abs(specific_roi)<0.1) and (abs(unspecific_ROI)<0.1):
        cat='No'
    else:
        cat='Spurious'
    return cat
  except:
    pass

def return_cat_index(serie, analysis, cat_index):
  from pandas import DataFrame
  try:
    serie_index = serie.value_counts(normalize=True).reindex(cat_index, fill_value=0)
    serie_index = DataFrame(serie_index).transpose()
    serie_index.columns=[analysis+"."+x for x in cat_index]
    return serie_index
  except:
    pass

def get_seed_path(path, scan_dir, seed): 
    from os.path import join
    from os import listdir
    seed_prefix = "_seed_name_"
    try:
        seed_path = join(path, scan_dir, seed_prefix + seed)
        seed_file = listdir(seed_path)[0]
        seed_final = join(seed_path, seed_file)
        return seed_final
    except:
        pass

def get_fd(tmp_listdir, scan_dir):
  from re import compile
  from pandas import read_csv 
  try: 
    r = compile(".*"+scan_dir)
    fd_file = list(filter(r.match, tmp_listdir))[0]
    fd = read_csv(fd_file, sep=",")["Mean"]
    fd_mean = fd.mean()
    return fd_mean
  except: 
    pass

#function to plot the seed maps. call get_seed_path and do_second_level
def plot_seed_map(data_dir, analysis_dir, seed_img_dir, analysis, df, bg_img, mask_img,seed,cut_coords):
  from os import makedirs
  from os.path import join
  output_nii = join(analysis_dir, 'group_SBA_nii')
  output_svg = join('../assets/plot', 'group_SBA_svg')
  makedirs(output_nii, exist_ok=True)
  makedirs(output_svg, exist_ok=True)
  p = join(data_dir, analysis, seed_img_dir)
  try:
    for i in df["rodent.ds"].unique():
      print("now doing ds "+str(i))
      print("getting list of seed maps")
      second_level_input = df[df["rodent.ds"]==i]["scan_dir"].apply(lambda x: get_seed_path(p, x, seed)).reset_index(drop=True) 
      second_level_input = [x for x in second_level_input if x is not None]
      filename_export = "ds-"+str(i)+"_analysis_"+analysis+"_seed-"+seed
      filename_path_nii = join(output_nii, filename_export)
      filename_path_svg = join(output_svg, filename_export)
      title = 'analysis: '+analysis+', seed: ' + seed + ', n = '+ str(len(second_level_input))
      do_second_level(second_level_input, bg_img, mask_img, title, cut_coords, filename_path_nii, filename_path_svg)
  except:
    pass

def do_second_level(second_level_input, bg_img, mask_img, title, cut_coords, filename_path_nii, filename_path_svg):
  from nilearn.glm.second_level import SecondLevelModel
  from nilearn.plotting import plot_stat_map
  from pandas import DataFrame
  try:
      design_matrix = DataFrame([1] * len(second_level_input), columns=['intercept'])
      second_level_model = SecondLevelModel(mask_img=mask_img)
      print("fitting second level model")
      second_level_model = second_level_model.fit(second_level_input,design_matrix=design_matrix)
      print("getting z map")
      z_map = second_level_model.compute_contrast(output_type='z_score')
      print("writing z map to "+filename_path_nii)
      z_map.to_filename(filename_path_nii+'.nii.gz')
      print("writing plot map to "+filename_path_svg)
      plot_stat_map(z_map, bg_img,title=title, threshold=1.9, vmax=5, symmetric_cbar=True, cmap='coolwarm',  black_bg=False, cut_coords=cut_coords,output_file=filename_path_svg+'.svg')
  except:
    pass

```

now defile some general purpose variables
```{python}

analysis_list = [ "gsr1", "gsr2", "gsr3","wmcsf1", "wmcsf2", "wmcsf3", "aCompCor1", "aCompCor2", "aCompCor3" ]  
motion_dir="motion_datasink/FD_csv"
frame_mask_dir = "frame_censoring_mask"
seed_ts_dir = "analysis_datasink/seed_timecourse_csv/"
seed_img_dir = "analysis_datasink/seed_correlation_maps/"

cat_index = ["Specific", "Non-specific", "Spurious", "No"]

seed_ref = "s1_r"
seed_specific = "s1_l"
seed_unspecific = "aca_r"
seed_thalamus = "vpm_r"

```


# this is the variable part. 
```{python}

#for rodent in ["mouse", "rat" ]:
rodent='rat'
print("#### NOW DOING " + rodent + " ####")
data_dir = "/project/4180000.36/awake/complete_output_"+rodent
bids_dir = "/project/4180000.36/awake/bids/"+rodent+"_complete"
analysis_dir = "/project/4180000.36/awake/analysis_"+rodent
bg_img = "../assets/template/"+rodent+"/template.nii.gz"
mask_img = "../assets/template/"+rodent+"/mask.nii.gz"
df = pd.read_csv("../assets/tables/"+rodent+"_metadata.tsv", sep="\t")
df["scan"] = "sub-0" + df["rodent.sub"].astype("str") + "_ses-" + df["rodent.session"].astype("str") + "_run-" + df["rodent.run"].astype("str")
df["scan_dir"] = "_split_name_" + df["scan"] + "_task-rest_bold" 
aidaqc = pd.read_csv("../assets/tables/"+rodent+"_caculated_features_func.csv", sep=",")
aidaqc = aidaqc.rename(columns={"tSNR (Averaged Brain ROI)": "aidaqc.tsnr", "Displacement factor (std of Mutual information)": "aidaqc.dist"})
aidaqc["scan"] = aidaqc["FileAddress"].apply(lambda x : x.split("func/")[1].split("_task")[0])
df = df.merge(aidaqc, on="scan")
df = df[df['exclude'] != 'y']
df_summary=pd.read_csv("../assets/tables/"+rodent+"_summary.tsv", sep="\t")
#first, let's extract some infomation about motion and summarize it per dataset
p = join(data_dir, motion_dir)
tmp_listdir = glob.glob(join(p,"*/*/*.csv"), recursive=True)
tmp_listdir_alt = glob.glob(join(p,"*/*.csv"), recursive=True)
tmp_listdir = tmp_listdir + tmp_listdir_alt 
df["fd.mean"]=df["scan"].apply(lambda x: get_fd(tmp_listdir, x))
tmp_listdir = glob.glob(join(bids_dir,"*/*/func/*.nii.gz"), recursive=True)
df["total.frames"]=df["scan"].apply(lambda x: total_frames(tmp_listdir, x))

print("#### MOTION ANALYISIS ####")
print("mean fd across all "+rodent+" datasets")
print(df["fd.mean"].mean())
df_summary = df_summary.join(df.groupby("rodent.ds")["fd.mean"].mean().rename('fd.mean'), on='rodent.ds')
print("mean fd per dataset")
print(df_summary[["rodent.ds", "fd.mean"]])
#now we run the analysis per denoising style, we extract the number of dropped frames, the s1-s1, s1-aca, and s1-thal correlations. finally we estimate connectivity specificity
df = get_fc_per_analysis(data_dir, df, analysis_list, frame_mask_dir, seed_ts_dir, seed_ref, seed_specific, seed_unspecific, seed_thalamus)
print("Number of dropped frames for each dataset and denoising method")
print("This corresponds to the following rabies flags for mice")
print("#gsr1: --frame_censoring FD_censoring=true,FD_threshold=0.1,DVARS_censoring=true")
print("#gsr2: --frame_censoring FD_censoring=true,FD_threshold=0.5,DVARS_censoring=true")
print("#gsr3: --frame_censoring FD_censoring=true,FD_threshold=0.5,DVARS_censoring=false")
#for analysis in analysis_list[0:3]:
#    print("Denoising method: " + analysis)
#    print("Mean number of dropped frames "+str(df["dropped.frames." + analysis].mean()))
#    print("Max number of dropped frames "+str(df["dropped.frames." + analysis].max()))
#    print("Mean relative number of dropped frames "+str(df["dropped.frames." + analysis].mean()/df["total.frames"].mean()))
#    print("Number of scans with dropped frames: " + str(len(df[df["dropped.frames." + analysis] > 0])))
df_summary = df_summary.join(df.groupby("rodent.ds")["total.frames"].mean(), on='rodent.ds')
df_summary = df_summary.join(df.groupby("rodent.ds")["dropped.frames.gsr1"].mean(), on='rodent.ds')
df_summary = df_summary.join(df.groupby("rodent.ds")["dropped.frames.gsr2"].mean(), on='rodent.ds')
df_summary = df_summary.join(df.groupby("rodent.ds")["dropped.frames.gsr3"].mean(), on='rodent.ds')
print("#### DENOISE ANALYSIS ####")
print("dropped frames per dataset")
print(df_summary[["rodent.ds", "total.frames", "dropped.frames.gsr1", "dropped.frames.gsr2", "dropped.frames.gsr3"]])
for analysis in analysis_list:
  df_summary = df_summary.join(df.groupby("rodent.ds")["s1.cat."+analysis].apply(lambda x: return_cat_index(x, analysis, cat_index)).droplevel(1), on='rodent.ds')
print("#### FC specifiticy analysis ####")
print("s1-s1 specificity analysis (only showing specific values)")
print(df_summary[["rodent.ds"]+[analysis+".Specific" for analysis in analysis_list]])
df_summary.to_csv("../assets/tables/"+rodent+"_summary_processed.tsv", sep="\t", index=False)
df.to_csv("../assets/tables/"+rodent+"_metadata_process.tsv", sep="\t", index=False)
#same values but with a more concise plotting style. Overall, denoising style did not impact the overall number of specific scans. once the analysis is complete with all scans, i will pick the better performing method to carry out a singular analysis 
print("#### make plots ####")
columns = ["s1.cat."+x for x in analysis_list]
specificity_denoise = pd.concat([df[col].value_counts(sort=False).reindex(cat_index, fill_value=0) for col in columns], axis=1)
specificity_denoise.columns=analysis_list
specificity_denoise = specificity_denoise/specificity_denoise.sum()
specificity_denoise_T = specificity_denoise.T
specificity_denoise_T.reset_index(level=0, inplace=True) 
specificity_denoise_T = specificity_denoise_T[["index"]+cat_index]
specificity_denoise_T.set_index('index').plot(kind='bar', stacked=True)
plt.savefig("../assets/plot/"+rodent+"_specificity.svg")
#make the standard s1-s1 / s1-aca connectivity plot.   
for analysis in analysis_list:
  ax = sns.jointplot(data=df, x='thal.specific.'+analysis, y='s1.unspecific.'+analysis)
  ax.fig.suptitle('FC specificity with ' + analysis)
  ax.fig.subplots_adjust(top=0.9)
  ax.ax_joint.set(xlabel='Specific ROI [r]', ylabel='Unspecific ROI [r]')
  ax.ax_joint.vlines(0.1,ymin=min(df['s1.unspecific.'+analysis]),ymax=max(df['s1.unspecific.'+analysis]),linestyles='dashed', color='black')
  ax.ax_joint.vlines(-0.1, -0.1,0.1,linestyles='dashed', color='black')
  ax.ax_joint.hlines(-0.1, -0.1,0.1,linestyles='dashed', color='black')
  ax.ax_joint.hlines(0.1, -0.1,xmax=max(df['thal.specific.'+analysis]),linestyles='dashed', color='black')
  ax.ax_marg_x.axvline(x=0.1, color='black')
  ax.ax_marg_y.axhline(y=0.1, color='black')
  plt.savefig("../assets/plot/specific/"+rodent+"_thal_specificity_"+analysis+".svg")
for analysis in analysis_list:
  ax = sns.jointplot(data=df, x='s1.specific.'+analysis, y='s1.unspecific.'+analysis)
  ax.fig.suptitle('FC specificity with ' + analysis)
  ax.fig.subplots_adjust(top=0.9)
  ax.ax_joint.set(xlabel='Specific ROI [r]', ylabel='Unspecific ROI [r]')
  ax.ax_joint.vlines(0.1,ymin=min(df['s1.unspecific.'+analysis]),ymax=max(df['s1.unspecific.'+analysis]),linestyles='dashed', color='black')
  ax.ax_joint.vlines(-0.1, -0.1,0.1,linestyles='dashed', color='black')
  ax.ax_joint.hlines(-0.1, -0.1,0.1,linestyles='dashed', color='black')
  ax.ax_joint.hlines(0.1, -0.1,xmax=max(df['s1.specific.'+analysis]),linestyles='dashed', color='black')
  ax.ax_marg_x.axvline(x=0.1, color='black')
  ax.ax_marg_y.axhline(y=0.1, color='black')
  plt.savefig("../assets/plot/specific/"+rodent+"_s1_specificity_"+analysis+".svg")
print("#### plot SBA maps ####")
#now use nilearn to make group average maps and plot them. 
seed_to_plot = pd.DataFrame({'seed': [seed_ref, seed_unspecific, seed_thalamus], 'cut_coords': [(3,1,2.5), (0.2,3.2,2.4), (1.6, 0.4, 0.6)]})
analysis_list = [ "gsr1",  "gsr3", "aCompCor1", "aCompCor3" ]  
for analysis in analysis_list:
  for index, row in seed_to_plot.iterrows():
      plot_seed_map(data_dir, analysis_dir, seed_img_dir, analysis, df, bg_img, mask_img,row["seed"],row["cut_coords"])

```

